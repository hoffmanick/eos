---
title: "FAUNMAP site taxonomy"
author: "Nick Hoffman"
date: "`r Sys.Date()`"
output: 
  html_document:
    df_print: paged
    css: db_by_db.css
    toc: true
    number_sections: true
    toc_depth: 1
    toc_float: true
    theme: journal
---

```{r, results='asis', echo = F}
toc_depth <- rmarkdown::metadata$output$html_document$toc_depth
sel <- paste0("h",(toc_depth+1):10, collapse = " > span, ")
cat(paste0("<style>",
           sel, 
           " > .header-section-number { display: none; } </style>"))
```



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(httr)
library(dplyr)
library(DT)
library(geojsonsf)
library(osmdata)
library(rosm)
library(rmapshaper)
library(tmap)
library(sf)
library(leaflet)
library(stringr)
library(wkb)
library(tidyverse)
library(neotoma2)
library(lubridate)
```

# Faunmap sites

This table shows all FAUNMAP sites as well as their geographic precision when known and their archaeological status.

```{r download-tables,message=FALSE,warning=FALSE,echo=FALSE}


tables = c("datasets","publications", "datasetpublications","collectionunits","datasetdatabases","constituentdatabases","sites","depenvttypes")



for (i in seq(length(tables))) {

  table = tables[[i]]
dslinks = content(GET(paste0("https://api.neotomadb.org/v2.0/data/dbtables?table=",table,"&limit=75000&offset=0")))$data



if (table == "publications") {
  dsl_df = matrix(nrow=length(dslinks),ncol=(length(dslinks[[1]]) - 2))
  for (j in seq(1,length(dslinks))) {
  for (k in seq((length(dslinks[[1]])) - 2)) {
    if (!is.null(dslinks[[j]][[k]])) {
      dsl_df[j,k] = dslinks[[j]][[k]]
    }
  }
}
}
else {
  dsl_df = matrix(nrow=length(dslinks),ncol=length(dslinks[[1]]))
for (j in seq(1,length(dslinks))) {
  for (k in seq(length(dslinks[[1]]))) {
    if (!is.null(dslinks[[j]][[k]])) {
      dsl_df[j,k] = dslinks[[j]][[k]]
    }
  }
}
}

dsl_df = as.data.frame(dsl_df)

if (table =="publications") {
names(dsl_df) = names(dslinks[[1]])[1:(length(dslinks[[1]])-2)]  }

else {
  names(dsl_df) = names(dslinks[[1]])  
}

assign(paste0(table,"_df"), dsl_df)
}

faun_sites = sites_df %>% dplyr::left_join(collectionunits_df, by=join_by(siteid)) %>% left_join(depenvttypes_df, by=join_by(depenvtid)) %>% left_join(datasets_df,by=join_by(collectionunitid)) %>% left_join(datasetdatabases_df,by=join_by(datasetid)) %>% left_join(constituentdatabases_df,by=join_by(databaseid)) %>% dplyr::filter(databaseid=='10') 

```



```{r smiths, echo=FALSE, message=FALSE,warning=FALSE}

states = read_sf("tl_2024_us_state.shp")
states = ms_simplify(states)

# https://www.digtech-llc.com/blog/2012/3/27/94-shovelbums-guide-part-15-the-smithsonian-trinomial-system.html

state_names = c("Alabama", "Alaska", "American Samoa", "Arizona", "Arkansas", "California", "Colorado","Connecticut","Delaware", "District of Columbia", "Federated States of Micronesia", "Florida", "Georgia","Guam","Hawaii","Idaho","Illinois","Indiana","Iowa","Kansas","Kentucky","Louisiana","Maine","Marshall Islands", "Maryland","Massachusetts","Michigan","Minnesota","Mississippi","Missouri","Montana","Nebraska","Nevada","New Hampshire","New Jersey","New Mexico","New York","North Carolina","North Dakota","Northern Mariana Islands","Ohio","Oklahoma","Oregon","Palau","Pennsylvania","Puerto Rico","Rhode Island","South Carolina","South Dakota","Tennessee","Texas","Utah","Vermont","Virgin Islands","Virginia","Washington","West Virginia","Wisconsin","Wyoming")

tris = c(1,49,NA,2,3,4,5,6,7,NA,NA,8,9,NA,50,10,11,12,13,14,15,16,17,NA,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,NA,33,34,35,NA,36,NA,37,38,39,40,41,42,43,NA,44,45,46,47,48)


state_tri_mapper=data.frame(names=state_names,trinom_num=tris) %>% dplyr::mutate(trinom_num = as.character(trinom_num))

state_tri_mapper = state_tri_mapper %>% dplyr::mutate(trinom_num = case_when(names=="Arizona" ~ "AZ", names=="California" ~ "CA", names=="New Mexico" ~ "LA",names=="Maine" ~ "ME",
         TRUE ~ trinom_num))


siteid=c("junk")
sitename=c("junk")
state=c("junk")
collectionunitid=c("junk")
geography=("junk")
potentials = data.frame(siteid=siteid,sitename=sitename,state=state,geography=geography, collectionunitid=collectionunitid)
for (num in seq(length(states[[1]]))) {

coordinates_sf = states[num,] %>% st_convex_hull()


coord_json = sf_geojson(coordinates_sf) %>% URLencode()


sites = content(GET(paste0("https://api.neotomadb.org/v2.0/data/sites?loc=",coord_json,"&limit=9999&offset=0")))$data

if (length(sites) > 0) {

idx = 0
for (i in seq(length(sites))) {
  for (j in seq(length(sites[[i]]$collectionunits))) {
    for (k in seq(length(sites[[i]]$collectionunits[[j]]$datasets))) {
    idx = idx + 1
    }
    }
}


sites_mat = matrix(nrow=idx,ncol=11)

idx2 = 0
for (i in seq(length(sites))) {
  for (j in seq(length(sites[[i]]$collectionunits))) {
    for (k in seq(length(sites[[i]]$collectionunits[[j]]$datasets))) {
    idx2 = idx2 + 1
    for (m in seq(5)) {
      if (!is.null(sites[[i]][[m]])) {
        sites_mat[[idx2, m]] = sites[[i]][[m]]
      }
    }
    
     if (!is.null(sites[[i]]$collectionunits[[j]]$handle)) {
        sites_mat[[idx2,6]] = sites[[i]]$collectionunits[[j]]$handle
     }
       if (!is.null(sites[[i]]$collectionunits[[j]]$collectionunit)) {
        sites_mat[[idx2,7]] = sites[[i]]$collectionunits[[j]]$collectionunit
       }
       if (!is.null(sites[[i]]$collectionunits[[j]]$collectionunitid)) {
        sites_mat[[idx2,8]] = sites[[i]]$collectionunits[[j]]$collectionunitid
       }
       if (!is.null(sites[[i]]$collectionunits[[j]]$collectionunittype)) {
        sites_mat[[idx2,9]] = sites[[i]]$collectionunits[[j]]$collectionunittype
       }
       if (!is.null(sites[[i]]$collectionunits[[j]]$dataset[[k]]$datasetid)) {
        sites_mat[[idx2,10]] = sites[[i]]$collectionunits[[j]]$dataset[[k]]$datasetid
       }
       if (!is.null(sites[[i]]$collectionunits[[j]]$dataset[[k]]$datasettype)) {
        sites_mat[[idx2,11]] = sites[[i]]$collectionunits[[j]]$dataset[[k]]$datasettype
       }
    }
  }
}

sites_state_df = as.data.frame(sites_mat)

names(sites_state_df) = c("siteid","sitename","sitedescription","geography","altitude","handle","collectionunit","collectionunitid","collectionunittype","datasetid","datasettype")

numb = state_tri_mapper %>% dplyr::filter(names == states$NAME[[num]]) %>% dplyr::select(trinom_num)

if (states$NAME[[num]] == "Vermont") {
  potentialsites = sites_state_df %>% dplyr::filter(str_detect(sitename, "VT")) %>% dplyr::select(siteid,sitename,geography,collectionunitid) %>% dplyr::mutate(state = states$NAME[[num]])
  potentials = rbind(potentials,potentialsites)
} else if (states$NAME[[num]] == "Rhode Island") {
  potentialsites = sites_state_df %>% dplyr::filter(str_detect(sitename, "RI")) %>% dplyr::select(siteid,sitename,geography,collectionunitid) %>% dplyr::mutate(state = states$NAME[[num]])
  potentials = rbind(potentials,potentialsites)
} else if (states$NAME[[num]] == "Connectictut") {
  potentialsites = sites_state_df %>% dplyr::filter(str_detect(sitename, "CT")| str_detect(sitename, "6")) %>% dplyr::select(siteid,sitename,geography,collectionunitid) %>% dplyr::mutate(state = states$NAME[[num]])
  potentials = rbind(potentials,potentialsites)
} else if (states$NAME[[num]] == "Arizona") {
  potentialsites = sites_state_df %>% dplyr::filter(str_detect(sitename, "[A-Za-z]{1,2}:[0-9]{1,2}")) %>% dplyr::select(siteid,sitename,geography,collectionunitid) %>% dplyr::mutate(state = states$NAME[[num]])
  potentials = rbind(potentials,potentialsites)
} else if (states$NAME[[num]] == "Alaska") {
  potentialsites = sites_state_df %>% dplyr::filter(str_detect(sitename, "[A-Za-z]{3}-[0-9]+")) %>% dplyr::select(siteid,sitename,geography,collectionunitid) %>% dplyr::mutate(state = states$NAME[[num]])
  potentials = rbind(potentials,potentialsites)
} else if (states$NAME[[num]] == "New York") {
  potentialsites = sites_state_df %>% dplyr::filter(str_detect(sitename, "\\d{5}")|
str_detect(sitename,"30")) %>% dplyr::select(siteid,sitename,geography,collectionunitid) %>% dplyr::mutate(state = states$NAME[[num]])
  potentials = rbind(potentials,potentialsites)
} else if (!is.na(numb[[1]])) {
potentialsites = sites_state_df %>% dplyr::filter(str_detect(sitename,as.character(numb[[1]]))) %>% dplyr::select(siteid,sitename,geography,collectionunitid) %>% dplyr::mutate(state = states$NAME[[num]])
potentials = rbind(potentials,potentialsites)
  } else {
  #print(paste0("Null mapper value for ", states$NAME[[num]]))
}}}


potentials = potentials %>% dplyr::filter(sitename != "junk") %>% dplyr::filter(!str_detect(sitename,"Jensen 1998"))  %>% dplyr::filter(!str_detect(sitename,"Riegel 1965")) %>% dplyr::filter(!str_detect(sitename,"Haile 8A")) %>% dplyr::filter(!str_detect(sitename,"Santa Fe River 8A")) %>% distinct() %>% dplyr::filter(!sitename %in% c("Site 66 (Delcourt et al. 1983)","Site 110 (G.M. Peterson 1978)","Site 10 (Mack, Bryant, and Pell 1978)","LRRB31","Site 106 (Swain unpublished)","Anthony Cave [MALB 29]","Baldy Peak Cave [MALB 29]","Solar Energy Generating Station II [1.76.42]","Luz Solar Trough [1.76.34]", "Site 13 (Delcourt et al. 1983)","Site 14 (Delcourt et al. 1983)","Site 66 (Delcourt et al. 1983)","CHUSKA29","CHUS29","Upper Alturas [UO Loc 2424; CAS Loc 36805]","Site 35 (Heusser 1978)","BECL360","Stand 45 (Mack and Bryant 1974]","Law's [MSv100]","Seven Springs [CE101x3]","Rock House [MS201]","Mobile Bay, MB0810-GC20","Spring Canyon [A-41]","Pratt Cave [TMM-41172]","Little Sunday Canyon Local Fauna [V5414]","Avery Ranch [s:5:8]","Big Juniper House [1595]","Badger House [1453]","Mesa Verde Site 875","La Poudre LP5 Site","SNMN5","SNMN15","ANIM5","ANIM35","COMO5","LPLT5","GATC26","Mile 49 Lac la Ronge Highway","Stations 49-55 (Lichti-Federovich and Ritchie 1968)","TK-49","49 [HFL49]","Valkenswaard N49","Mosquito Lake Site, [PSM-00049]","BOREA24, Mile 49","LR49","ALTAK49","ABD249","Island 35 [10-Q-7]","Hancock Ditch (ditch #39)","Tunica Bayou Site 22","NLA06608-1232","JHMN24 (McAndrews and Wright 1969)","NLA06608-0439","Twin Peaks, AZ","Tucson Mountains, Pima Co., AZ","Vijdt Polder (B49D0349)","Borteldonk (B49F0399)","Halsteren (B49B0566)","Ossendrecht 49D20-1","Shangri-La Bog","Oskino-09","'White-2 (Le4) Pond'","Mud Pond (VT)")) %>%
  dplyr::filter(!str_detect(sitename,"Mount Evans Surface")) %>%  dplyr::filter(!str_detect(sitename,"Elliot-Fisk")) %>%  dplyr::filter(!str_detect(sitename,"Raux-Feui")) %>% dplyr::filter(!str_detect(sitename,"Exposure")) %>%
  dplyr::filter(!str_detect(sitename,"LDDsite")) %>%  dplyr::filter(!str_detect(sitename,"Pond,")) %>%
  dplyr::filter(!str_detect(sitename,"Begin boardwalk")) %>% dplyr::filter(!str_detect(sitename,"unpublished")) %>%
  dplyr::filter(!str_detect(sitename,"Colonel's Island Site")) %>%
  dplyr::filter(!str_detect(sitename,"Delcourt")) %>% dplyr::filter((state !="California") | state == "California" & str_detect(sitename,"CA"))


us_bounds = read_sf("cb_2018_us_nation_20m.shp")


unique_pot = geojson_sf(potentials$geography) %>% cbind(potentials) %>% distinct(siteid,.keep_all=TRUE) %>% st_transform(crs=st_crs(us_bounds)) %>% st_filter(us_bounds)


unique_pot = unique_pot %>% left_join(datasets_df,by=join_by("collectionunitid")) %>% left_join(datasetdatabases_df,by=join_by("datasetid")) %>% left_join(constituentdatabases_df, by=join_by("databaseid"))

faun_smiths = unique_pot %>% dplyr::filter(databasename =="FAUNMAP") %>% distinct(sitename,.keep_all=TRUE)

num_smiths = length(faun_smiths[[1]])
```



```{r depenv, echo=FALSE,warning=FALSE,message=FALSE}



archaeo_faun = faun_sites %>% dplyr::filter(depenvthigherid == "1") %>% distinct(siteid,depenvt,.keep_all = TRUE)


arch_sfc = st_as_sfc(hex2raw(archaeo_faun$geog),EWKB=TRUE)
arch_sf = st_as_sf(archaeo_faun,geom=arch_sfc) %>% dplyr::select(!geog)
```

```{r sensitive, message=FALSE,echo=FALSE,warning=FALSE}

  
dictionary = c("human","Human","Homo","homo","indian","Indian","native","Native","indigenous","Indigenous","mound","Mound","buri","Buri","bury","Bury","archaeo","Archaeo","person","Person","people","People","cairn","Cairn")

dictionary = as.data.frame(dictionary)
dictionary <- dictionary[order(dictionary$dictionary),]


matches_sitename <- grep(paste(dictionary,collapse="|"), 
                        faun_sites$sitename)


sitename_results= faun_sites[matches_sitename,] %>% distinct(siteid,.keep_all = TRUE)
num_sacredsites = length(sitename_results[[1]])

```

```{r origifuzz, echo=FALSE,warning=FALSE,message=FALSE}


precision_df <- data.frame(
  Code = c("E", "QA", "QP", "QC", "T"),
  Description = c(
    "Exact (lat/long)",
    "Quadrangle Approximate",
    "Quadrangle Precise",
    "Quad. in center of county",
    "USGS Township Coord."
  )
)


locs = read.csv("LOCALITY.txt",header=FALSE)
recov = read.csv("L_RECOV.txt",header=FALSE)
depo = read.csv("DEPOSIT.txt",header=FALSE)
faun= read.csv("FAUNAL.txt",header=FALSE)

names(faun) = c("locid","analysisunit","taxon","confidence","mni","nisp","context","modifications")
names(depo) = c("locid","analysisunit","recoverymethod","depsys","depenv","facies","mixing")

names(locs) = c("locid","sitename_f","alternate_name","state/province","county","sitenumber","coded_by","recdatecreated","recdatemodified","notes","geographic_precision","quadrangle","quadrangle_size","lat","lon","altitude","repository")


faun_sites2 = faun_sites %>% dplyr::mutate(faun_name = str_replace(sitename, "\\s*\\[.*$", ""))  %>% dplyr::mutate(extracted = str_extract(sitename,  "(?:(?:\\[[^\\]]*\\]){2}|\\[[^\\]]*\\])$")) %>% dplyr::mutate(extracted = str_replace_all(extracted,  "[\\[\\]]", "")) %>% distinct(siteid,sitename,faun_name,extracted) %>% left_join(locs, by=join_by("faun_name" == "sitename_f")) %>% group_by(faun_name) %>% dplyr::filter(sitenumber == extracted | n() == 1 | is.na(extracted)) %>% dplyr::select(siteid,sitename,faun_name,extracted,sitenumber,geographic_precision,quadrangle,quadrangle_size,lat,lon,repository) %>% dplyr::mutate(sitename_sensitive = case_when(siteid %in% sitename_results$siteid ~ "yes", TRUE ~ "no")) %>% mutate(smith = case_when(siteid %in% faun_smiths$siteid ~ "yes", TRUE ~ "no")) %>% mutate(archaeo = case_when(siteid %in% archaeo_faun$siteid ~ "yes", TRUE ~ "no"))

faun_dt = faun_sites2 %>% select(siteid,sitename,faun_name,extracted,sitenumber,geographic_precision,sitename_sensitive,smith,archaeo)

datatable(faun_dt,rownames=FALSE)

```

# Highest Priority: very archaeo and exact

The highest priority sites have 

* sensitive site name, 
* archaeological depositional environment, 
* a smithsonian trinomial, and 
* exact geographic precision:

```{r dinaa, echo=FALSE,warning=FALSE,message=FALSE}

priority1 = faun_dt %>% dplyr::filter(sitename_sensitive == "yes" & archaeo=="yes" & smith =="yes" & geographic_precision == "E")

datatable(priority1,rownames=FALSE)


```

# High Priority: archaeo and exact

Still high priority are those sites which have at least one of

* sensitive site name,
* archaeological depositional environment, or
* smithsonian trinomial

and also have exact geographic precision.

```{r stillhigh, echo=FALSE,warning=FALSE,message=FALSE}

priority2 = faun_dt %>% dplyr::filter((sitename_sensitive == "yes" | archaeo=="yes" | smith =="yes") & !(sitename_sensitive == "yes" & archaeo=="yes" & smith =="yes" ) & geographic_precision == "E")

datatable(priority2,rownames=FALSE)
```

# High Priority: archaeo and unknown

Also high priority are sites that have at least one of

* sensitive site name,
* archaeological depositional environment, or
* smithsonian trinomial

and have unknown geographic precision:

```{r stillhigh2, echo=FALSE,warning=FALSE,message=FALSE}

priority3 = faun_dt %>% dplyr::filter((sitename_sensitive == "yes" | archaeo=="yes" | smith =="yes") & is.na(geographic_precision))

datatable(priority3,rownames=FALSE)
```

# Lower Priority: archaeo and QA/QP//Q/T

These sites are archaeological by some indicator and are fuzzed to the quadrangle level. Well, "Q" is a little ambiguous. Only five sites have geographic precision Q and there's no metadata about what it means. To be safe, we'll assume it means quadrangle level fuzzing.

```{r lower, echo=FALSE,warning=FALSE,message=FALSE}

priority4 = faun_dt %>% dplyr::filter((sitename_sensitive == "yes" | archaeo=="yes" | smith =="yes") & geographic_precision %in% c("QA","QP","T","Q"))

datatable(priority4,rownames=FALSE)
```

# Low priority: Paleontological and Archaeological/QC

The lowest priority are those archaeological sites already obfuscated to the county level or any sites which fail all tests for archaeological status.

```{r lowerstill, echo=FALSE,warning=FALSE,message=FALSE}

priority5 = faun_dt %>% dplyr::filter(((sitename_sensitive == "yes" | archaeo=="yes" | smith =="yes") & geographic_precision %in% c("QC")) | ((sitename_sensitive == "no" & archaeo=="no" & smith =="no")))

datatable(priority5,rownames=FALSE)
```
